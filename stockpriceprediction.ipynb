{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q1.Read the file named “prices.csv” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-05 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-07 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date symbol        open       close         low        high  \\\n",
       "0  2016-01-05 00:00:00   WLTW  123.430000  125.839996  122.309998  126.250000   \n",
       "1  2016-01-06 00:00:00   WLTW  125.239998  119.980003  119.940002  125.540001   \n",
       "2  2016-01-07 00:00:00   WLTW  116.379997  114.949997  114.930000  119.739998   \n",
       "3  2016-01-08 00:00:00   WLTW  115.480003  116.620003  113.500000  117.440002   \n",
       "4  2016-01-11 00:00:00   WLTW  117.010002  114.970001  114.089996  117.330002   \n",
       "\n",
       "      volume  \n",
       "0  2163600.0  \n",
       "1  2386400.0  \n",
       "2  2489500.0  \n",
       "3  2006300.0  \n",
       "4  1408600.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To enable plotting graphs in Jupyter notebook\n",
    "%matplotlib inline\n",
    "# Numerical libraries\n",
    "import numpy as np\n",
    "# to handle data in form of rows and columns\n",
    "import pandas as pd \n",
    "# importing plotting libraries\n",
    "import matplotlib.pyplot as plt \n",
    "#importing seaborn for statistical plots\n",
    "import seaborn as sns\n",
    "prj6_df_org = pd.read_csv(\"\\Project\\\\prices.csv\")\n",
    "prj6_df = prj6_df_org\n",
    "prj6_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((851264, 7), 5958848)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prj6_df.shape,prj6_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 851264 entries, 0 to 851263\n",
      "Data columns (total 7 columns):\n",
      "date      851264 non-null object\n",
      "symbol    851264 non-null object\n",
      "open      851264 non-null float64\n",
      "close     851264 non-null float64\n",
      "low       851264 non-null float64\n",
      "high      851264 non-null float64\n",
      "volume    851264 non-null float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "prj6_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>851264.0</td>\n",
       "      <td>7.083699e+01</td>\n",
       "      <td>8.369588e+01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.384000e+01</td>\n",
       "      <td>5.277000e+01</td>\n",
       "      <td>7.988000e+01</td>\n",
       "      <td>1.584440e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>851264.0</td>\n",
       "      <td>7.085711e+01</td>\n",
       "      <td>8.368969e+01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.385000e+01</td>\n",
       "      <td>5.280000e+01</td>\n",
       "      <td>7.989000e+01</td>\n",
       "      <td>1.578130e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>851264.0</td>\n",
       "      <td>7.011841e+01</td>\n",
       "      <td>8.287729e+01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.348000e+01</td>\n",
       "      <td>5.223000e+01</td>\n",
       "      <td>7.911000e+01</td>\n",
       "      <td>1.549940e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>851264.0</td>\n",
       "      <td>7.154348e+01</td>\n",
       "      <td>8.446550e+01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.419000e+01</td>\n",
       "      <td>5.331000e+01</td>\n",
       "      <td>8.061000e+01</td>\n",
       "      <td>1.600930e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>851264.0</td>\n",
       "      <td>5.415113e+06</td>\n",
       "      <td>1.249468e+07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.221500e+06</td>\n",
       "      <td>2.476250e+06</td>\n",
       "      <td>5.222500e+06</td>\n",
       "      <td>8.596434e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std   min           25%  \\\n",
       "open    851264.0  7.083699e+01  8.369588e+01  0.85  3.384000e+01   \n",
       "close   851264.0  7.085711e+01  8.368969e+01  0.86  3.385000e+01   \n",
       "low     851264.0  7.011841e+01  8.287729e+01  0.83  3.348000e+01   \n",
       "high    851264.0  7.154348e+01  8.446550e+01  0.88  3.419000e+01   \n",
       "volume  851264.0  5.415113e+06  1.249468e+07  0.00  1.221500e+06   \n",
       "\n",
       "                 50%           75%           max  \n",
       "open    5.277000e+01  7.988000e+01  1.584440e+03  \n",
       "close   5.280000e+01  7.989000e+01  1.578130e+03  \n",
       "low     5.223000e+01  7.911000e+01  1.549940e+03  \n",
       "high    5.331000e+01  8.061000e+01  1.600930e+03  \n",
       "volume  2.476250e+06  5.222500e+06  8.596434e+08  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prj6_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories in date = 3524\n",
      "Number of categories in symbol = 501\n"
     ]
    }
   ],
   "source": [
    "cat_col = []  # list to hold the categorical features\n",
    "for i in prj6_df.columns:  # Loop to go through each and every column name\n",
    "    if prj6_df[i].dtype == object:  # check if the column is of object type\n",
    "        cat_col.append(i)  # append the ones that satisfy above condition to the list\n",
    "    prj6_df.loc[0:3, cat_col]\n",
    "for i in cat_col:\n",
    "    print(f'Number of categories in {i} = {len(prj6_df[i].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q2.Drop all the rows with null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#There are no null values in the data to drop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q3.Drop columns: “date”, “volume” and “symbol” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         open       close         low        high\n",
       "0  123.430000  125.839996  122.309998  126.250000\n",
       "1  125.239998  119.980003  119.940002  125.540001\n",
       "2  116.379997  114.949997  114.930000  119.739998\n",
       "3  115.480003  116.620003  113.500000  117.440002\n",
       "4  117.010002  114.970001  114.089996  117.330002"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prj6_df = prj6_df.drop(columns= ['date','volume','symbol'])\n",
    "prj6_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q4.Get “close” as the target column and rest of the columns as features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = prj6_df.drop(columns= ['close'])\n",
    "target = prj6_df.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((851264, 3), (851264,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape,target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q5.Split the data into training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((595884, 3), (255380, 3), (595884,), (255380,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape),(X_test.shape),(y_train.shape),(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q6.Scale the data (features only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "y_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q7.Convert features and labels to numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((595884, 3), (595884,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18066333, -0.17499134, -0.18062612],\n",
       "       [ 1.07367034,  1.05975655,  1.05661349],\n",
       "       [ 0.93261591,  0.94551272,  0.94321271],\n",
       "       ...,\n",
       "       [ 0.07817502,  0.08097235,  0.07656551],\n",
       "       [ 0.20836981,  0.21244906,  0.20013579],\n",
       "       [-0.19438687, -0.19644215, -0.19635322]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55.950001, 159.929993, 148.630005, ...,  77.790001,  88.43    ,\n",
       "        53.889999])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q8.Reshape the features to make it suitable for input in the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#No Reshape required for this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q9.Define the sequential model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x29496686cf8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add a flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x29496686cf8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(tensorflow.keras.layers.Flatten())\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add Dense layer with linear activation function and one neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x294a80a5a20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = 3))\n",
    "model.add(Dense(1,))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q10. Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x294a80a5a20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q10.1 Use loss as “mean squared error”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x294a80a5a20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q10.2 Use optimizer as “sgd”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x294a80a5a20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics = ['accuracy'])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q11.Print summary of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 595884 samples\n",
      "Epoch 1/3\n",
      "595884/595884 [==============================] - 121s 203us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "595884/595884 [==============================] - 118s 198us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "595884/595884 [==============================] - 118s 199us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size = 10, epochs = 3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q12.Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 595884 samples\n",
      "Epoch 1/5\n",
      "595884/595884 [==============================] - 149s 249us/sample - loss: 40.4997 - accuracy: 5.0345e-06\n",
      "Epoch 2/5\n",
      "595884/595884 [==============================] - 145s 243us/sample - loss: 2.9362 - accuracy: 5.0345e-06\n",
      "Epoch 3/5\n",
      "595884/595884 [==============================] - 144s 241us/sample - loss: 2.3648 - accuracy: 5.0345e-06\n",
      "Epoch 4/5\n",
      "595884/595884 [==============================] - 151s 254us/sample - loss: 1.9960 - accuracy: 5.0345e-06\n",
      "Epoch 5/5\n",
      "595884/595884 [==============================] - 161s 269us/sample - loss: 1.9990 - accuracy: 5.0345e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x294a915a5f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the NN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(32, activation = 'relu', input_dim = 3))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compiling the NN\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X, y, batch_size = 10, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q12.1 Use 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 595884 samples\n",
      "Epoch 1/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6951 - accuracy: 5.0345e-06\n",
      "Epoch 2/50\n",
      "595884/595884 [==============================] - 15s 25us/sample - loss: 0.7679 - accuracy: 5.0345e-06\n",
      "Epoch 3/50\n",
      "595884/595884 [==============================] - 15s 24us/sample - loss: 0.7140 - accuracy: 5.0345e-06\n",
      "Epoch 4/50\n",
      "595884/595884 [==============================] - 16s 27us/sample - loss: 0.7042 - accuracy: 5.0345e-06\n",
      "Epoch 5/50\n",
      "595884/595884 [==============================] - 18s 30us/sample - loss: 0.7026 - accuracy: 5.0345e-06\n",
      "Epoch 6/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6545 - accuracy: 5.0345e-06\n",
      "Epoch 7/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6543 - accuracy: 5.0345e-06\n",
      "Epoch 8/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.6398 - accuracy: 5.0345e-06\n",
      "Epoch 9/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.6571 - accuracy: 5.0345e-06\n",
      "Epoch 10/50\n",
      "595884/595884 [==============================] - 16s 28us/sample - loss: 0.6463 - accuracy: 5.0345e-06\n",
      "Epoch 11/50\n",
      "595884/595884 [==============================] - 16s 27us/sample - loss: 0.6114 - accuracy: 5.0345e-06\n",
      "Epoch 12/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6292 - accuracy: 5.0345e-06\n",
      "Epoch 13/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6111 - accuracy: 5.0345e-06\n",
      "Epoch 14/50\n",
      "595884/595884 [==============================] - 16s 28us/sample - loss: 0.6074 - accuracy: 5.0345e-06\n",
      "Epoch 15/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.6214 - accuracy: 5.0345e-06\n",
      "Epoch 16/50\n",
      "595884/595884 [==============================] - 16s 27us/sample - loss: 0.6275 - accuracy: 5.0345e-06\n",
      "Epoch 17/50\n",
      "595884/595884 [==============================] - 15s 25us/sample - loss: 0.5876 - accuracy: 5.0345e-06\n",
      "Epoch 18/50\n",
      "595884/595884 [==============================] - 16s 27us/sample - loss: 0.6060 - accuracy: 5.0345e-06\n",
      "Epoch 19/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.5997 - accuracy: 5.0345e-06\n",
      "Epoch 20/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6025 - accuracy: 5.0345e-06\n",
      "Epoch 21/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6143 - accuracy: 5.0345e-06\n",
      "Epoch 22/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.6117 - accuracy: 5.0345e-06 - loss: 0.6143 - \n",
      "Epoch 23/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.6145 - accuracy: 5.0345e-06\n",
      "Epoch 24/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.5888 - accuracy: 5.0345e-06\n",
      "Epoch 25/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.5849 - accuracy: 5.0345e-06\n",
      "Epoch 26/50\n",
      "595884/595884 [==============================] - 18s 30us/sample - loss: 0.6127 - accuracy: 5.0345e-06\n",
      "Epoch 27/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6007 - accuracy: 5.0345e-06\n",
      "Epoch 28/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.5808 - accuracy: 5.0345e-06\n",
      "Epoch 29/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.5861 - accuracy: 5.0345e-06\n",
      "Epoch 30/50\n",
      "595884/595884 [==============================] - 15s 26us/sample - loss: 0.6023 - accuracy: 5.0345e-06\n",
      "Epoch 31/50\n",
      "595884/595884 [==============================] - 16s 27us/sample - loss: 0.5916 - accuracy: 5.0345e-06\n",
      "Epoch 32/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.6126 - accuracy: 5.0345e-06\n",
      "Epoch 33/50\n",
      "595884/595884 [==============================] - 18s 30us/sample - loss: 0.5871 - accuracy: 5.0345e-06\n",
      "Epoch 34/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.6135 - accuracy: 5.0345e-06\n",
      "Epoch 35/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.5866 - accuracy: 5.0345e-06\n",
      "Epoch 36/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.5895 - accuracy: 5.0345e-06\n",
      "Epoch 37/50\n",
      "595884/595884 [==============================] - 18s 29us/sample - loss: 0.5890 - accuracy: 5.0345e-06\n",
      "Epoch 38/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.5885 - accuracy: 5.0345e-06\n",
      "Epoch 39/50\n",
      "595884/595884 [==============================] - 16s 26us/sample - loss: 0.5983 - accuracy: 5.0345e-06\n",
      "Epoch 40/50\n",
      "595884/595884 [==============================] - 19s 31us/sample - loss: 0.6281 - accuracy: 5.0345e-06\n",
      "Epoch 41/50\n",
      "595884/595884 [==============================] - 17s 29us/sample - loss: 0.5789 - accuracy: 5.0345e-06\n",
      "Epoch 42/50\n",
      "595884/595884 [==============================] - 18s 29us/sample - loss: 0.5664 - accuracy: 5.0345e-06\n",
      "Epoch 43/50\n",
      "595884/595884 [==============================] - 15s 26us/sample - loss: 0.5990 - accuracy: 5.0345e-06\n",
      "Epoch 44/50\n",
      "595884/595884 [==============================] - 16s 27us/sample - loss: 0.5815 - accuracy: 5.0345e-06\n",
      "Epoch 45/50\n",
      "595884/595884 [==============================] - 16s 27us/sample - loss: 0.5630 - accuracy: 5.0345e-06\n",
      "Epoch 46/50\n",
      "595884/595884 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 5.0437e- - 15s 26us/sample - loss: 0.5708 - accuracy: 5.0345e-06\n",
      "Epoch 47/50\n",
      "595884/595884 [==============================] - 14s 24us/sample - loss: 0.5898 - accuracy: 5.0345e-06\n",
      "Epoch 48/50\n",
      "595884/595884 [==============================] - 17s 28us/sample - loss: 0.5758 - accuracy: 5.0345e-06\n",
      "Epoch 49/50\n",
      "595884/595884 [==============================] - 18s 29us/sample - loss: 0.5620 - accuracy: 5.0345e-06\n",
      "Epoch 50/50\n",
      "595884/595884 [==============================] - 18s 31us/sample - loss: 0.5827 - accuracy: 5.0345e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x294a835eba8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size = 100, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q12.2 Use batch size as 128 for fast training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 595884 samples\n",
      "Epoch 1/5\n",
      "595884/595884 [==============================] - 13s 21us/sample - loss: 0.5529 - accuracy: 5.0345e-06\n",
      "Epoch 2/5\n",
      "595884/595884 [==============================] - 12s 20us/sample - loss: 0.5519 - accuracy: 5.0345e-06\n",
      "Epoch 3/5\n",
      "595884/595884 [==============================] - 11s 19us/sample - loss: 0.5654 - accuracy: 5.0345e-06\n",
      "Epoch 4/5\n",
      "595884/595884 [==============================] - 12s 20us/sample - loss: 0.5518 - accuracy: 5.0345e-06\n",
      "Epoch 5/5\n",
      "595884/595884 [==============================] - 11s 19us/sample - loss: 0.5441 - accuracy: 5.0345e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x294a83cc4e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q13.Do predictions on test data and evaluate the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "[[7560.747 ]\n",
      " [2926.0276]\n",
      " [2844.796 ]\n",
      " ...\n",
      " [6831.443 ]\n",
      " [3089.0884]\n",
      " [4547.8525]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q14.Do some custom predictions on your own manual inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.37561214]\n",
      " [154.54877   ]]\n"
     ]
    }
   ],
   "source": [
    "ManualTest_df=pd.read_csv(\"Project\\\\Test.csv\")\n",
    "sc=StandardScaler()\n",
    "M_Test = sc.fit_transform(ManualTest_df)\n",
    "manual_pred = model.predict(M_Test)\n",
    "print(manual_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
